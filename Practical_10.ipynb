{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "299831e6485829a5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Implementing Transformer Models\n",
    "## Practical X\n",
    "Carel van Niekerk & Hsien-Chin Lin\n",
    "\n",
    "6-11.01.2025\n",
    "\n",
    "---\n",
    "\n",
    "In this practical we will evaluate the performance of the transformer model we trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db3becedbe2f606",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Autoregressive Generation\n",
    "\n",
    "In order to generate a translation we will use the autoregressive property of the transformer model. We will use the following procedure to generate a translation:\n",
    "\n",
    "1. Encode the source sentence using the encoder.\n",
    "2. Initialize the decoder with the encoded source sentence.\n",
    "3. Generate the first token of the translation by passing the start of text token through the decoder.\n",
    "4. Pass the generated token through the decoder to generate the next token and repeat until the end of text token is generated.\n",
    "\n",
    "#### 1.1. Greedy Decoding\n",
    "\n",
    "The simplest way to generate a translation is to use greedy decoding. In greedy decoding we simply select the token with the highest probability at each step.\n",
    "\n",
    "### 2. Evaluation\n",
    "\n",
    "In order to evaluate the performance of the model we will use the BLEU score. The BLEU score is a metric that measures the similarity between two sentences. See the [huggingface evaluate documentation](https://huggingface.co/spaces/evaluate-metric/bleu) for more information on the BLEU score, as well as details on using the metric in huggingface evaluate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a20b8711fe743b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Exercises\n",
    "\n",
    "1. Implement the autoregressive generation procedure described above using your transformer model. (Using greedy decoding, remember to add a maximum length to the generation procedure to prevent infinite generation.)\n",
    "2. Generate translations for the test set (or a subset of the test set) of WMT17 German-English.\n",
    "3. Evaluate the BLEU score of your model on the test set (or a subset of the test set) of WMT17 German-English.\n",
    "4. Evaluate some of the translations generated by your model. Do they make sense? What are some of the errors made by your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c8e9c54ce28429",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
